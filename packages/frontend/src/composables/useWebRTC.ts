import { ref, onUnmounted } from 'vue'
import { useEventBus } from '@/utils/event-bus'

export interface WebRTCConfig {
    iceServers: RTCIceServer[]
}

export interface MediaDevice {
    deviceId: string
    label: string
    kind: MediaDeviceKind
}

export interface CallState {
    isConnecting: boolean
    isConnected: boolean
    isLocalVideoEnabled: boolean
    isLocalAudioEnabled: boolean
    isRemoteVideoEnabled: boolean
    isRemoteAudioEnabled: boolean
    isScreenSharing: boolean
    error: string | null
}

export const useWebRTC = () => {
    const eventBus = useEventBus()

    // WebRTC —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    let peerConnection: RTCPeerConnection | null = null // –ù–µ —Ä–µ–∞–∫—Ç–∏–≤–Ω—ã–π - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏ composable
    let localStream: MediaStream | null = null // –ù–µ —Ä–µ–∞–∫—Ç–∏–≤–Ω—ã–π - —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ JavaScript
    let remoteStream: MediaStream | null = null // –ù–µ —Ä–µ–∞–∫—Ç–∏–≤–Ω—ã–π - —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ JavaScript
    let currentTargetUserId: string | number | null = null // ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∑–≤–æ–Ω–∫–∞
    let pendingIceCandidates: RTCIceCandidateInit[] = [] // –ë—É—Ñ–µ—Ä –¥–ª—è ICE candidates –¥–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ peer connection
    let selectedVideoDeviceId: string | null = null // ID –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞–º–µ—Ä—ã
    let selectedAudioDeviceId: string | null = null // ID –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
    let screenStream: MediaStream | null = null // –ü–æ—Ç–æ–∫ –¥–ª—è screen sharing
    let originalVideoTrack: MediaStreamTrack | null = null // –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–∏–¥–µ–æ —Ç—Ä–µ–∫ (–∫–∞–º–µ—Ä–∞) –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
    const callState = ref<CallState>({
        isConnecting: false,
        isConnected: false,
        isLocalVideoEnabled: false,
        isLocalAudioEnabled: false,
        isRemoteVideoEnabled: false,
        isRemoteAudioEnabled: false,
        isScreenSharing: false,
        error: null,
    })

    // –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –º–µ–¥–∏–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
    const availableVideoDevices = ref<MediaDevice[]>([])
    const availableAudioDevices = ref<MediaDevice[]>([])
    const currentVideoDevice = ref<string | null>(null)
    const currentAudioDevice = ref<string | null>(null)

    // –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ICE —Å–µ—Ä–≤–µ—Ä–æ–≤ (–º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏)
    const defaultConfig: WebRTCConfig = {
        iceServers: [
            { urls: 'stun:stun.l.google.com:19302' },
            { urls: 'stun:stun1.l.google.com:19302' },
            { urls: 'stun:stun2.l.google.com:19302' },
        ],
    }

    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WebRTC —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    const initializePeerConnection = (config: WebRTCConfig = defaultConfig) => {
        try {
            peerConnection = new RTCPeerConnection(config)

            // –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π WebRTC
            peerConnection.onicecandidate = (event) => {
                if (event.candidate && currentTargetUserId) {
                    console.log('ICE candidate:', event.candidate)
                    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º ICE candidate —á–µ—Ä–µ–∑ WebSocket —Å targetUserId
                    eventBus.emit('webrtc_ice_candidate', {
                        candidate: event.candidate,
                        targetUserId: currentTargetUserId,
                    })
                }
            }

            peerConnection.oniceconnectionstatechange = () => {
                const state = peerConnection?.iceConnectionState
                console.log('ICE connection state:', state)

                if (!state) return

                switch (state as RTCIceConnectionState) {
                    case 'checking':
                    case 'new':
                        callState.value.isConnecting = true
                        callState.value.isConnected = false
                        callState.value.error = null
                        // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                        eventBus.emit('webrtc_connection_state_changed', {
                            state: 'connecting',
                            isConnecting: true,
                            isConnected: false,
                        })
                        break
                    case 'connected':
                    case 'completed':
                        callState.value.isConnecting = false
                        callState.value.isConnected = true
                        callState.value.error = null
                        // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                        eventBus.emit('webrtc_connection_state_changed', {
                            state: 'connected',
                            isConnecting: false,
                            isConnected: true,
                        })
                        break
                    case 'disconnected':
                    case 'failed':
                    case 'closed':
                        callState.value.isConnecting = false
                        callState.value.isConnected = false
                        if (state === 'failed') {
                            callState.value.error = 'Connection failed'
                        }
                        // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ —Ä–∞–∑—Ä—ã–≤–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                        eventBus.emit('webrtc_connection_state_changed', {
                            state: state,
                            isConnecting: false,
                            isConnected: false,
                            error: state === 'failed' ? 'Connection failed' : null,
                        })
                        break
                }
            }

            peerConnection.ontrack = (event) => {
                console.log('üé• ontrack: Remote track received:', event)
                if (event.streams && event.streams[0]) {
                    remoteStream = event.streams[0]
                    console.log(
                        'üé• ontrack: Remote stream set, tracks:',
                        remoteStream.getTracks().length,
                    )

                    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã —Ç—Ä–µ–∫–æ–≤
                    event.streams[0].getTracks().forEach((track) => {
                        console.log(`üé• Remote track: ${track.kind}, enabled: ${track.enabled}`)
                        if (track.kind === 'video') {
                            callState.value.isRemoteVideoEnabled = track.enabled
                        } else if (track.kind === 'audio') {
                            callState.value.isRemoteAudioEnabled = track.enabled
                        }
                    })

                    // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è UI
                    console.log('üé• ontrack: emitting webrtc_remote_stream_updated event')
                    eventBus.emit('webrtc_remote_stream_updated', { stream: remoteStream })
                    console.log('üé• ontrack: event emitted')
                }
            }

            peerConnection.ondatachannel = (event) => {
                console.log('Data channel received:', event.channel)
                // –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É data channel –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
            }

            return peerConnection
        } catch (error) {
            console.error('Failed to initialize peer connection:', error)
            callState.value.error = 'Failed to initialize connection'
            return null
        }
    }

    // –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ–¥–∏–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
    const getMediaDevices = async (): Promise<{
        videoDevices: MediaDevice[]
        audioDevices: MediaDevice[]
    }> => {
        try {
            const devices = await navigator.mediaDevices.enumerateDevices()

            const videoDevices: MediaDevice[] = devices
                .filter((device) => device.kind === 'videoinput')
                .map((device) => ({
                    deviceId: device.deviceId,
                    label: device.label || `Camera ${device.deviceId.slice(0, 8)}`,
                    kind: device.kind,
                }))

            const audioDevices: MediaDevice[] = devices
                .filter((device) => device.kind === 'audioinput')
                .map((device) => ({
                    deviceId: device.deviceId,
                    label: device.label || `Microphone ${device.deviceId.slice(0, 8)}`,
                    kind: device.kind,
                }))

            availableVideoDevices.value = videoDevices
            availableAudioDevices.value = audioDevices

            console.log('üìπ Available video devices:', videoDevices)
            console.log('üé§ Available audio devices:', audioDevices)

            return { videoDevices, audioDevices }
        } catch (error) {
            console.error('Failed to get media devices:', error)
            return { videoDevices: [], audioDevices: [] }
        }
    }

    // –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –º–µ–¥–∏–∞ (–∫–∞–º–µ—Ä–∞/–º–∏–∫—Ä–æ—Ñ–æ–Ω)
    const getUserMedia = async (constraints: MediaStreamConstraints) => {
        try {
            callState.value.error = null
            console.log('üìπ getUserMedia: requesting media with constraints:', constraints)
            const stream = await navigator.mediaDevices.getUserMedia(constraints)
            localStream = stream
            console.log('üìπ getUserMedia: got stream with tracks:', stream.getTracks().length)

            // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–µ–¥–∏–∞
            stream.getTracks().forEach((track) => {
                console.log(`üìπ Track: ${track.kind}, enabled: ${track.enabled}`)
                if (track.kind === 'video') {
                    callState.value.isLocalVideoEnabled = track.enabled
                } else if (track.kind === 'audio') {
                    callState.value.isLocalAudioEnabled = track.enabled
                }
            })

            // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è UI
            console.log('üìπ getUserMedia: emitting webrtc_local_stream_updated event')
            eventBus.emit('webrtc_local_stream_updated', { stream: localStream })
            console.log('üìπ getUserMedia: event emitted')

            return stream
        } catch (error) {
            console.error('Failed to get user media:', error)
            callState.value.error = 'Failed to access camera/microphone'
            throw error
        }
    }

    // –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∑–≤–æ–Ω–∫—É - –ø–æ–ª—É—á–µ–Ω–∏–µ –º–µ–¥–∏–∞ –ø–æ—Ç–æ–∫–∞ –±–µ–∑ –æ—Ç–ø—Ä–∞–≤–∫–∏ offer
    const prepareCall = async (callType: 'video' | 'audio', targetUserId: string | number) => {
        try {
            callState.value.isConnecting = true
            callState.value.error = null

            // –°–æ—Ö—Ä–∞–Ω—è–µ–º targetUserId –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ ICE –∫–∞–Ω–¥–∏–¥–∞—Ç–∞—Ö
            currentTargetUserId = targetUserId

            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º peer connection
            const pc = initializePeerConnection()
            if (!pc) throw new Error('Failed to initialize peer connection')

            // –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –º–µ–¥–∏–∞ —Å —É—á–µ—Ç–æ–º –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
            const constraints: MediaStreamConstraints = {
                audio: selectedAudioDeviceId
                    ? { deviceId: { exact: selectedAudioDeviceId } }
                    : true,
                video:
                    callType === 'video'
                        ? selectedVideoDeviceId
                            ? { deviceId: { exact: selectedVideoDeviceId } }
                            : true
                        : false,
            }

            const stream = await getUserMedia(constraints)

            // –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–∫–∏ –≤ peer connection
            stream.getTracks().forEach((track) => {
                pc.addTrack(track, stream)
            })

            console.log('Call prepared, media stream ready')
            return true
        } catch (error) {
            console.error('Failed to prepare call:', error)
            callState.value.isConnecting = false
            callState.value.error = 'Failed to prepare call'
            return false
        }
    }

    // –û—Ç–ø—Ä–∞–≤–∫–∞ offer –ø–æ—Å–ª–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏
    const sendOffer = async (callType: 'video' | 'audio', targetUserId: string | number) => {
        try {
            if (!peerConnection) {
                throw new Error('Peer connection not initialized')
            }

            // –°–æ–∑–¥–∞–µ–º offer
            const offer = await peerConnection.createOffer()
            await peerConnection.setLocalDescription(offer)

            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º offer —á–µ—Ä–µ–∑ WebSocket
            eventBus.emit('webrtc_call_offer', {
                targetUserId,
                callType,
                offer: offer,
            })

            console.log('Offer sent')
            return true
        } catch (error) {
            console.error('Failed to send offer:', error)
            callState.value.error = 'Failed to send offer'
            return false
        }
    }

    // –ù–∞—á–∞–ª–æ –∏—Å—Ö–æ–¥—è—â–µ–≥–æ –∑–≤–æ–Ω–∫–∞ (–æ–±—ä–µ–¥–∏–Ω—è–µ—Ç prepareCall –∏ sendOffer)
    const startCall = async (callType: 'video' | 'audio', targetUserId: string | number) => {
        try {
            const prepared = await prepareCall(callType, targetUserId)
            if (!prepared) return false

            const sent = await sendOffer(callType, targetUserId)
            if (!sent) return false

            console.log('Call started, offer sent')
            return true
        } catch (error) {
            console.error('Failed to start call:', error)
            callState.value.isConnecting = false
            callState.value.error = 'Failed to start call'
            return false
        }
    }

    // –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –ø—Ä–∏–Ω—è—Ç–∏—é –∑–≤–æ–Ω–∫–∞ - –ø–æ–ª—É—á–µ–Ω–∏–µ –º–µ–¥–∏–∞ –ø–æ—Ç–æ–∫–∞ –±–µ–∑ –æ—Ç–ø—Ä–∞–≤–∫–∏ answer
    const prepareAcceptCall = async (
        callType: 'video' | 'audio',
        offer: RTCSessionDescriptionInit,
        targetUserId: string | number,
    ) => {
        try {
            callState.value.isConnecting = true
            callState.value.error = null

            // –°–æ—Ö—Ä–∞–Ω—è–µ–º targetUserId –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ ICE –∫–∞–Ω–¥–∏–¥–∞—Ç–∞—Ö
            currentTargetUserId = targetUserId

            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º peer connection
            const pc = initializePeerConnection()
            if (!pc) throw new Error('Failed to initialize peer connection')

            // –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –º–µ–¥–∏–∞ —Å —É—á–µ—Ç–æ–º –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
            const constraints: MediaStreamConstraints = {
                audio: selectedAudioDeviceId
                    ? { deviceId: { exact: selectedAudioDeviceId } }
                    : true,
                video:
                    callType === 'video'
                        ? selectedVideoDeviceId
                            ? { deviceId: { exact: selectedVideoDeviceId } }
                            : true
                        : false,
            }

            const stream = await getUserMedia(constraints)

            // –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–∫–∏ –≤ peer connection
            stream.getTracks().forEach((track) => {
                pc.addTrack(track, stream)
            })

            console.log('Local stream set up in prepareAcceptCall, tracks added to peer connection')

            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É–¥–∞–ª–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (offer)
            await pc.setRemoteDescription(offer)

            // –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã–µ ICE candidates –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ remote description
            await applyPendingIceCandidates()

            console.log('Call prepared for acceptance, media stream ready')
            return true
        } catch (error) {
            console.error('Failed to prepare accept call:', error)
            callState.value.isConnecting = false
            callState.value.error = 'Failed to prepare accept call'
            return false
        }
    }

    // –û—Ç–ø—Ä–∞–≤–∫–∞ answer –ø–æ—Å–ª–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏
    const sendAnswer = async (targetUserId: string | number) => {
        try {
            if (!peerConnection) {
                throw new Error('Peer connection not initialized')
            }

            // –°–æ–∑–¥–∞–µ–º answer
            const answer = await peerConnection.createAnswer()
            await peerConnection.setLocalDescription(answer)

            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º answer —á–µ—Ä–µ–∑ WebSocket —Å targetUserId
            console.log('Emitting webrtc_call_answer event with targetUserId:', targetUserId)
            eventBus.emit('webrtc_call_answer', {
                answer: answer,
                targetUserId: targetUserId,
            })

            console.log('Answer sent')
            return true
        } catch (error) {
            console.error('Failed to send answer:', error)
            callState.value.error = 'Failed to send answer'
            return false
        }
    }

    // –ü—Ä–∏–Ω—è—Ç–∏–µ –≤—Ö–æ–¥—è—â–µ–≥–æ –∑–≤–æ–Ω–∫–∞ (–æ–±—ä–µ–¥–∏–Ω—è–µ—Ç prepareAcceptCall –∏ sendAnswer)
    const acceptCall = async (
        callType: 'video' | 'audio',
        offer: RTCSessionDescriptionInit,
        targetUserId: string | number,
    ) => {
        try {
            const prepared = await prepareAcceptCall(callType, offer, targetUserId)
            if (!prepared) return false

            const sent = await sendAnswer(targetUserId)
            if (!sent) return false

            console.log('Call accepted, answer sent')
            return true
        } catch (error) {
            console.error('Failed to accept call:', error)
            callState.value.isConnecting = false
            callState.value.error = 'Failed to accept call'
            return false
        }
    }

    // –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö ICE candidates
    const applyPendingIceCandidates = async () => {
        if (!peerConnection || pendingIceCandidates.length === 0) {
            return
        }

        console.log(`Applying ${pendingIceCandidates.length} pending ICE candidates`)

        for (const candidate of pendingIceCandidates) {
            try {
                await peerConnection.addIceCandidate(candidate)
                console.log('Pending ICE candidate added successfully')
            } catch (error) {
                console.error('Failed to add pending ICE candidate:', error)
            }
        }

        // –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
        pendingIceCandidates = []
    }

    // –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ answer
    const handleAnswer = async (answer: RTCSessionDescriptionInit) => {
        try {
            if (!peerConnection) {
                throw new Error('Peer connection not initialized')
            }

            await peerConnection.setRemoteDescription(answer)
            console.log('Answer processed successfully')

            // –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã–µ ICE candidates –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ remote description
            await applyPendingIceCandidates()
        } catch (error) {
            console.error('Failed to handle answer:', error)
            callState.value.error = 'Failed to process answer'
        }
    }

    // –û–±—Ä–∞–±–æ—Ç–∫–∞ ICE candidate
    const handleIceCandidate = async (candidate: RTCIceCandidateInit) => {
        try {
            if (!peerConnection) {
                console.warn('Peer connection not initialized yet, buffering ICE candidate')
                pendingIceCandidates.push(candidate)
                return
            }

            // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ª–∏ remote description
            if (!peerConnection.remoteDescription) {
                console.warn('Remote description not set yet, buffering ICE candidate')
                pendingIceCandidates.push(candidate)
                return
            }

            await peerConnection.addIceCandidate(candidate)
            console.log('ICE candidate added successfully')
        } catch (error) {
            console.error('Failed to add ICE candidate:', error)
        }
    }

    // –°–º–µ–Ω–∞ –≤–∏–¥–µ–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    const switchVideoDevice = async (deviceId: string) => {
        try {
            if (!localStream) {
                console.warn('No local stream available for video device switch')
                return false
            }

            selectedVideoDeviceId = deviceId
            currentVideoDevice.value = deviceId

            // –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π –≤–∏–¥–µ–æ –ø–æ—Ç–æ–∫ —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
            const newStream = await navigator.mediaDevices.getUserMedia({
                video: { deviceId: { exact: deviceId } },
                audio: false, // –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–∏–¥–µ–æ
            })

            const newVideoTrack = newStream.getVideoTracks()[0]
            const oldVideoTrack = localStream.getVideoTracks()[0]

            if (newVideoTrack && peerConnection) {
                // –ó–∞–º–µ–Ω—è–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫ –≤ peer connection
                const sender = peerConnection
                    .getSenders()
                    .find((s) => s.track && s.track.kind === 'video')

                if (sender) {
                    await sender.replaceTrack(newVideoTrack)
                }

                // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π —Ç—Ä–µ–∫
                if (oldVideoTrack) {
                    oldVideoTrack.stop()
                    localStream.removeTrack(oldVideoTrack)
                }

                // –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–∫ –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫
                localStream.addTrack(newVideoTrack)

                // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                callState.value.isLocalVideoEnabled = newVideoTrack.enabled

                // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
                eventBus.emit('webrtc_local_stream_updated', { stream: localStream })

                console.log('üìπ Video device switched successfully to:', deviceId)
                return true
            }

            return false
        } catch (error) {
            console.error('Failed to switch video device:', error)
            callState.value.error = 'Failed to switch camera'
            return false
        }
    }

    // –°–º–µ–Ω–∞ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    const switchAudioDevice = async (deviceId: string) => {
        try {
            if (!localStream) {
                console.warn('No local stream available for audio device switch')
                return false
            }

            selectedAudioDeviceId = deviceId
            currentAudioDevice.value = deviceId

            // –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫ —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
            const newStream = await navigator.mediaDevices.getUserMedia({
                audio: { deviceId: { exact: deviceId } },
                video: false, // –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ
            })

            const newAudioTrack = newStream.getAudioTracks()[0]
            const oldAudioTrack = localStream.getAudioTracks()[0]

            if (newAudioTrack && peerConnection) {
                // –ó–∞–º–µ–Ω—è–µ–º –∞—É–¥–∏–æ —Ç—Ä–µ–∫ –≤ peer connection
                const sender = peerConnection
                    .getSenders()
                    .find((s) => s.track && s.track.kind === 'audio')

                if (sender) {
                    await sender.replaceTrack(newAudioTrack)
                }

                // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π —Ç—Ä–µ–∫
                if (oldAudioTrack) {
                    oldAudioTrack.stop()
                    localStream.removeTrack(oldAudioTrack)
                }

                // –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–∫ –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫
                localStream.addTrack(newAudioTrack)

                // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                callState.value.isLocalAudioEnabled = newAudioTrack.enabled

                // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
                eventBus.emit('webrtc_local_stream_updated', { stream: localStream })

                console.log('üé§ Audio device switched successfully to:', deviceId)
                return true
            }

            return false
        } catch (error) {
            console.error('Failed to switch audio device:', error)
            callState.value.error = 'Failed to switch microphone'
            return false
        }
    }

    // –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ
    const toggleLocalVideo = () => {
        if (localStream) {
            const videoTrack = localStream.getVideoTracks()[0]
            if (videoTrack) {
                videoTrack.enabled = !videoTrack.enabled
                callState.value.isLocalVideoEnabled = videoTrack.enabled
            }
        }
    }

    // –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ
    const toggleLocalAudio = () => {
        if (localStream) {
            const audioTrack = localStream.getAudioTracks()[0]
            if (audioTrack) {
                audioTrack.enabled = !audioTrack.enabled
                callState.value.isLocalAudioEnabled = audioTrack.enabled
            }
        }
    }

    // –ù–∞—á–∞–ª–æ screen sharing
    const startScreenShare = async () => {
        try {
            if (!localStream || !peerConnection) {
                console.warn('No local stream or peer connection available for screen sharing')
                return false
            }

            // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ screen sharing
            screenStream = await navigator.mediaDevices.getDisplayMedia({
                video: {
                    cursor: 'always',
                } as MediaTrackConstraints,
                audio: false,
            })

            const screenTrack = screenStream.getVideoTracks()[0]

            if (screenTrack) {
                // –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–∏–¥–µ–æ —Ç—Ä–µ–∫ (–∫–∞–º–µ—Ä—É)
                const currentVideoTrack = localStream.getVideoTracks()[0]
                if (currentVideoTrack) {
                    originalVideoTrack = currentVideoTrack
                }

                // –ó–∞–º–µ–Ω—è–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫ –≤ peer connection
                const sender = peerConnection
                    .getSenders()
                    .find((s) => s.track && s.track.kind === 'video')

                if (sender) {
                    await sender.replaceTrack(screenTrack)
                }

                // –ó–∞–º–µ–Ω—è–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
                if (currentVideoTrack) {
                    localStream.removeTrack(currentVideoTrack)
                }
                localStream.addTrack(screenTrack)

                // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                callState.value.isScreenSharing = true
                callState.value.isLocalVideoEnabled = true

                // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∫—É screen sharing –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º —á–µ—Ä–µ–∑ UI –±—Ä–∞—É–∑–µ—Ä–∞
                screenTrack.onended = () => {
                    console.log('Screen sharing stopped by user')
                    stopScreenShare()
                }

                // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
                eventBus.emit('webrtc_local_stream_updated', { stream: localStream })

                console.log('üñ•Ô∏è Screen sharing started successfully')
                return true
            }

            return false
        } catch (error) {
            console.error('Failed to start screen sharing:', error)
            callState.value.error = 'Failed to start screen sharing'
            return false
        }
    }

    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ screen sharing –∏ –≤–æ–∑–≤—Ä–∞—Ç –∫ –∫–∞–º–µ—Ä–µ
    const stopScreenShare = async () => {
        try {
            if (!localStream || !peerConnection || !screenStream) {
                console.warn('No screen stream to stop')
                return false
            }

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º screen sharing –ø–æ—Ç–æ–∫
            screenStream.getTracks().forEach((track) => {
                track.stop()
            })

            // –£–±–∏—Ä–∞–µ–º screen track –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            const screenTrack = localStream.getVideoTracks()[0]
            if (screenTrack) {
                localStream.removeTrack(screenTrack)
            }

            // –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–∏–¥–µ–æ —Ç—Ä–µ–∫, –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –µ–≥–æ
            if (originalVideoTrack) {
                // –ó–∞–º–µ–Ω—è–µ–º —Ç—Ä–µ–∫ –≤ peer connection
                const sender = peerConnection
                    .getSenders()
                    .find((s) => s.track && s.track.kind === 'video')

                if (sender) {
                    await sender.replaceTrack(originalVideoTrack)
                }

                // –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫ –æ–±—Ä–∞—Ç–Ω–æ –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫
                localStream.addTrack(originalVideoTrack)
                originalVideoTrack = null
            } else {
                // –ï—Å–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ –Ω–µ—Ç, –ø–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ —Å –∫–∞–º–µ—Ä—ã
                const constraints: MediaStreamConstraints = {
                    video: selectedVideoDeviceId
                        ? { deviceId: { exact: selectedVideoDeviceId } }
                        : true,
                    audio: false,
                }

                const newStream = await navigator.mediaDevices.getUserMedia(constraints)
                const newVideoTrack = newStream.getVideoTracks()[0]

                if (newVideoTrack) {
                    const sender = peerConnection
                        .getSenders()
                        .find((s) => s.track && s.track.kind === 'video')

                    if (sender) {
                        await sender.replaceTrack(newVideoTrack)
                    }

                    localStream.addTrack(newVideoTrack)
                }
            }

            // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            callState.value.isScreenSharing = false
            callState.value.isLocalVideoEnabled = true

            screenStream = null

            // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            eventBus.emit('webrtc_local_stream_updated', { stream: localStream })

            console.log('üñ•Ô∏è Screen sharing stopped, camera restored')
            return true
        } catch (error) {
            console.error('Failed to stop screen sharing:', error)
            callState.value.error = 'Failed to stop screen sharing'
            return false
        }
    }

    // –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –∫–∞–º–µ—Ä–æ–π –∏ screen sharing
    const toggleScreenShare = async () => {
        if (callState.value.isScreenSharing) {
            return await stopScreenShare()
        } else {
            return await startScreenShare()
        }
    }

    // –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–≤–æ–Ω–∫–∞
    const endCall = (reason?: string, skipEmitEvent = false) => {
        try {
            const targetUserId = currentTargetUserId

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–∫–∏
            if (localStream) {
                localStream.getTracks().forEach((track) => {
                    track.stop()
                })
                localStream = null
            }

            // –ó–∞–∫—Ä—ã–≤–∞–µ–º peer connection
            if (peerConnection) {
                peerConnection.close()
                peerConnection = null
            }

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º screen sharing –µ—Å–ª–∏ –∞–∫—Ç–∏–≤–µ–Ω
            if (screenStream) {
                screenStream.getTracks().forEach((track) => {
                    track.stop()
                })
                screenStream = null
            }

            // –û—á–∏—â–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–∏–¥–µ–æ —Ç—Ä–µ–∫
            if (originalVideoTrack) {
                originalVideoTrack.stop()
                originalVideoTrack = null
            }

            // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            callState.value = {
                isConnecting: false,
                isConnected: false,
                isLocalVideoEnabled: false,
                isLocalAudioEnabled: false,
                isRemoteVideoEnabled: false,
                isRemoteAudioEnabled: false,
                isScreenSharing: false,
                error: null,
            }

            remoteStream = null
            pendingIceCandidates = [] // –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä ICE candidates

            // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–≤–æ–Ω–∫–∞, –µ—Å–ª–∏ –µ—Å—Ç—å targetUserId –∏ –Ω–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–±—ã—Ç–∏–µ
            if (targetUserId && !skipEmitEvent) {
                console.log('Emitting webrtc_call_end event for targetUserId:', targetUserId)
                eventBus.emit('webrtc_call_end', {
                    targetUserId,
                    reason: reason || 'call_ended',
                })
            } else if (skipEmitEvent) {
                console.log('Skipping webrtc_call_end event emission (local cleanup only)')
            }

            // –≠–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –æ–± –æ—á–∏—Å—Ç–∫–µ —Å—Ç—Ä–∏–º–æ–≤
            eventBus.emit('webrtc_streams_cleared', {})

            // –û—á–∏—â–∞–µ–º ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ—Å–ª–µ —ç–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–±—ã—Ç–∏—è
            currentTargetUserId = null

            console.log('Call ended successfully')
        } catch (error) {
            console.error('Error ending call:', error)
        }
    }

    // –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏
    onUnmounted(() => {
        endCall()
    })

    // –ì–µ—Ç—Ç–µ—Ä—ã –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–æ—Ç–æ–∫–∞–º
    const getLocalStream = () => {
        console.log('getLocalStream called, returning:', !!localStream)
        return localStream
    }
    const getRemoteStream = () => {
        console.log('getRemoteStream called, returning:', !!remoteStream)
        return remoteStream
    }

    return {
        // –°–æ—Å—Ç–æ—è–Ω–∏–µ
        callState,

        // –ì–µ—Ç—Ç–µ—Ä—ã –¥–ª—è –º–µ–¥–∏–∞ –ø–æ—Ç–æ–∫–æ–≤
        getLocalStream,
        getRemoteStream,

        // –ú–µ–¥–∏–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        availableVideoDevices,
        availableAudioDevices,
        currentVideoDevice,
        currentAudioDevice,
        getMediaDevices,
        switchVideoDevice,
        switchAudioDevice,

        // –ú–µ—Ç–æ–¥—ã
        prepareCall,
        sendOffer,
        startCall,
        prepareAcceptCall,
        sendAnswer,
        acceptCall,
        handleAnswer,
        handleIceCandidate,
        toggleLocalVideo,
        toggleLocalAudio,
        startScreenShare,
        stopScreenShare,
        toggleScreenShare,
        endCall,
    }
}
